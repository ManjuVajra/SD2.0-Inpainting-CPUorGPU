{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyMb8jEA4lTnH9uOse47QdJ1"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"B84keXL2PB-G"},"outputs":[],"source":["!pip install torchvision\n","!pip install diffusers\n","!pip install transformers\n","!pip install accelerate\n","!pip install ftfy\n","!pip install gradio\n","!pip install imageio\n","!pip install modin[all]"]},{"cell_type":"code","source":["from diffusers import StableDiffusionInpaintPipeline\n","import gradio as gr\n","import numpy as np\n","import imageio\n","from PIL import Image\n","import torch\n","import modin.pandas as pd\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","pipe = StableDiffusionInpaintPipeline.from_pretrained(\"stabilityai/stable-diffusion-2-inpainting\", safety_checker=None)\n","pipe = pipe.to(device)\n","\n","def resize(height,img):\n","  baseheight = height\n","  img = Image.open(img)\n","  hpercent = (baseheight/float(img.size[1]))\n","  wsize = int((float(img.size[0])*float(hpercent)))\n","  img = img.resize((wsize,baseheight), Image.LANCZOS)\n","  return img\n","\n","def predict(source_img, prompt, negative_prompt):\n","    imageio.imwrite(\"data.png\", source_img[\"image\"])\n","    imageio.imwrite(\"data_mask.png\", source_img[\"mask\"])\n","    src = resize(512, \"data.png\")\n","    src.save(\"src.png\")\n","    mask = resize(512, \"data_mask.png\")  \n","    mask.save(\"mask.png\")\n","    image = pipe(prompt=prompt, negative_prompt=negative_prompt, image=src, mask_image=mask, num_inference_steps=20).images[0]\n","    return image\n","\n","title=\"Stable Diffusion 2.0 Inpainting CPU\"\n","description=\"Inpainting with Stable Diffusion 2.0 <br />Warning: Slow process... ~10 min inference time.<br> <b>Please use 512x512 or 768x768 square .png image as input to avoid memory error!!!</b>\"\n","gr.Interface(fn=predict, inputs=[gr.Image(source=\"upload\", type=\"numpy\", tool=\"sketch\", elem_id=\"source_container\"), gr.Textbox(label='What you want the AI to Generate, 77 Token limit'), gr.Textbox(label='What you Do Not want the AI to generate')], outputs='image', title=title, description=description, article = \"Code Monkey: <a href=\\\"https://huggingface.co/Manjushri\\\">Manjushri</a>\").launch(max_threads=True, debug=True)"],"metadata":{"id":"2_NdTFgBPTcf"},"execution_count":null,"outputs":[]}]}